# Creating dfs0 Files with MIKE IO

After processing your time series data in Python—perhaps by selecting specific periods, resampling, or cleaning anomalies—you'll often need to save it back into a DHI-compatible format. `mikeio` allows you to create new `.dfs0` files from your Pandas DataFrames or `mikeio` `DataArray` objects.

## Why Create dfs0 Files?

Key reasons to create `.dfs0` files include:

*   **Interoperability:** Save processed data for use in MIKE modeling software (e.g., MIKE+, MIKE Zero).
*   **Archiving:** Store cleaned or derived time series in a standard DHI format.
*   **Sharing:** Share data with colleagues who use MIKE software.
*   **Workflow Integration:** Output from one Python script can become input for another MIKE-based process.

## Preparing Your Pandas DataFrame for dfs0 Creation

Before writing to a `.dfs0` file, ensure your Pandas DataFrame is correctly structured:

1.  **`DatetimeIndex`:** The DataFrame must have a `pd.DatetimeIndex`. This will form the time axis of the `.dfs0` file.
2.  **Columns as Items:** Each column in the DataFrame will become a data item in the `.dfs0` file.
3.  **Data Types:** Ensure data in columns is numeric (float or integer) as typically expected in `.dfs0` files for sensor readings or model results.
4.  **`NaN` Values:** Decide how to handle `NaN` values. `mikeio` can write `NaN`s (they become delete values in the dfs0 file), but ensure this is the desired behavior for the intended use of the dfs0 file. You might have already handled NaNs during data cleaning.

## Creating a dfs0 File from DataArrays

The most common way to create a `.dfs0` file with `mikeio` is by first constructing `mikeio.DataArray` objects for each item you want to save. Each `DataArray` combines the data with its time information and crucial metadata (item name, type, and unit).

```python
#| echo: true
#| output: true
#| eval: false # Assumes a DataFrame 'cleaned_df' exists
# For demonstration, let's create a sample 'cleaned_df'
# import pandas as pd
# import numpy as np
# time_idx = pd.date_range("2024-01-01", periods=5, freq="H")
# cleaned_df = pd.DataFrame({
#     "Discharge_HQ": np.array([10.1, 10.5, 10.3, 10.6, 10.4]),
#     "WaterLevel_WL": np.array([2.3, 2.4, 2.35, 2.45, 2.42])
# }, index=time_idx)
# print("Sample DataFrame to save:")
# print(cleaned_df)

import mikeio
from mikeio.eum import EUMType, EUMUnit # EUM: Engineering Unit Mappings

# Output filepath for the new dfs0 file
output_dfs0_filepath = "data/processed_timeseries.dfs0"
# Ensure 'data' directory exists (if not, create it or save to current dir)
# from pathlib import Path
# Path("data").mkdir(exist_ok=True)


# Create a list to hold mikeio.DataArray objects
data_arrays_to_write = []

# --- Create DataArray for the 'Discharge_HQ' column ---
# 1. Define ItemInfo: name, type, unit
item_info_discharge = mikeio.ItemInfo(
    name="River_Discharge", # Name as it will appear in dfs0
    eum_type=EUMType.Discharge, 
    eum_unit=EUMUnit.cubic_meter_per_second
)
# 2. Create DataArray
da_discharge = mikeio.DataArray(
    data=cleaned_df["Discharge_HQ"], # Pandas Series from your DataFrame
    time=cleaned_df.index,          # DatetimeIndex from your DataFrame
    item=item_info_discharge
)
data_arrays_to_write.append(da_discharge)


# --- Create DataArray for the 'WaterLevel_WL' column ---
item_info_wl = mikeio.ItemInfo(
    name="Stage_Height", 
    eum_type=EUMType.Water_Level, 
    eum_unit=EUMUnit.meter
)
da_wl = mikeio.DataArray(
    data=cleaned_df["WaterLevel_WL"],
    time=cleaned_df.index,
    item=item_info_wl
)
data_arrays_to_write.append(da_wl)


# Write the list of DataArrays to a dfs0 file
# The function might be mikeio.write_dfs0(), mikeio.Dataset(data_arrays_to_write).to_dfs(), or similar.
# Based on common mikeio patterns, mikeio.write_dfs0 is plausible.
# Or using Dataset().to_dfs():
# ds_to_write = mikeio.Dataset(data=data_arrays_to_write, time=cleaned_df.index)
# ds_to_write.to_dfs(output_dfs0_filepath)

# Let's assume a direct write function if available for simplicity, or use Dataset.
# If writing a list of DataArrays directly:
mikeio.write_dfs0(output_dfs0_filepath, data_arrays_to_write)

print(f"\nSuccessfully created dfs0 file: {output_dfs0_filepath}")
```

**Explanation:**

1.  **`import mikeio` and `from mikeio.eum import EUMType, EUMUnit`**: Import necessary components. `EUMType` and `EUMUnit` are enumerations that help you specify standard engineering types (e.g., Water Level, Discharge) and units (e.g., meter, cubic meter per second).
2.  **`item_info_... = mikeio.ItemInfo(...)`**: For each column (item) you want to save:
    *   Create an `ItemInfo` object.
    *   `name`: The desired name for the item in the `.dfs0` file.
    *   `eum_type`: The physical type of the data (e.g., `EUMType.Water_Level`).
    *   `eum_unit`: The unit of measurement (e.g., `EUMUnit.meter`).
3.  **`da_... = mikeio.DataArray(...)`**:
    *   Create a `DataArray` object.
    *   `data`: The Pandas Series (column) containing the actual data values.
    *   `time`: The `DatetimeIndex` from your DataFrame.
    *   `item`: The `ItemInfo` object you just created for this item.
4.  **`data_arrays_to_write.append(da_...)`**: Collect all `DataArray` objects in a list.
5.  **`mikeio.write_dfs0(output_dfs0_filepath, data_arrays_to_write)`**: This function (or a similar one like `Dataset(...).to_dfs()`) takes the output file path and the list of `DataArray` objects and writes the `.dfs0` file.

::: {.callout-note title="Importance of EUM Types and Units"}
Specifying correct `EUMType` and `EUMUnit` is crucial for ensuring your `.dfs0` file is correctly interpreted by MIKE software and other tools.

*   You can explore available types and units by inspecting `EUMType` and `EUMUnit` (e.g., `[member.name for member in EUMType]`).
*   Refer to DHI documentation for guidance on appropriate EUM codes for your data. If unsure, `EUMType.Undefined` and `EUMUnit.Undefined` can be used, but providing specific information is better.
:::

::: {.callout-tip title="Simpler Writing with `mikeio.Dataset`"}
An alternative and often more structured way is to first create a `mikeio.Dataset` from your `DataArray`s, and then use the dataset's `to_dfs()` method:

```python
#| echo: true
#| output: false
#| eval: false
# Assuming data_arrays_to_write is a list of DataArray objects
# and cleaned_df.index is the common DatetimeIndex

# dataset_to_write = mikeio.Dataset(data=data_arrays_to_write, time=cleaned_df.index)
# dataset_to_write.to_dfs(output_dfs0_filepath)
# print(f"Successfully created dfs0 file using Dataset: {output_dfs0_filepath}")
```

This approach is particularly useful if your data arrays share the same time axis, which is typical for data originating from a single DataFrame.
:::

## Verifying the Output

After creating the `.dfs0` file, it's good practice to verify its contents:

1.  **Open in MIKE Software:** If you have MIKE Zero, MIKE View, or other DHI tools, try opening the generated `.dfs0` file to check its structure and data.
2.  **Read it back with `mikeio`:**

    ```python
    #| echo: true
    #| output: true
    #| eval: false # Assumes output_dfs0_filepath is defined from previous step
    # print(f"\nVerifying the created file: {output_dfs0_filepath}")
    # ds_check = mikeio.read(output_dfs0_filepath)
    # df_check = ds_check.to_dataframe()

    # print("Contents of the newly created dfs0 file (head):")
    # print(df_check.head())

    # print("\nItems in the verified file:")
    # for item in ds_check.items:
    #    print(f"- Name: {item.name}, Type: {item.type.name}, Unit: {item.unit.name}")
    ```

This simple check helps confirm that the file was written correctly and contains the expected data and metadata.

## Video - Creating a dfs0 File from Pandas

*This section would ideally contain a short video (5-10 mins).*

**Video Description:** This video would demonstrate:

*   Starting with a processed Pandas DataFrame (e.g., after cleaning or resampling).
*   Creating `mikeio.ItemInfo` objects for each column, specifying names, EUM types, and EUM units.
*   Creating `mikeio.DataArray` objects from the DataFrame columns and item info.
*   Using `mikeio.write_dfs0()` or `Dataset.to_dfs()` to save the data to a new `.dfs0` file.
*   Briefly verifying the created file by reading it back with `mikeio` or showing it in a simple DHI tool if feasible.

---
comments: false
---