# Creating `dfs0` Files from `pandas` DataFrames

After you've meticulously processed your time series data in `pandas`—perhaps by resampling, cleaning, or validating it—you'll often need to save it back into a `.dfs0` file. This format is standard for MIKE+ and other DHI software, ensuring your data is ready for use in modeling workflows. The `mikeio` package provides a straightforward way to accomplish this.

The general process involves a few key steps:
1.  Ensuring your `pandas` DataFrame is correctly prepared.
2.  Converting each relevant column (which is a `pandas` Series) from your DataFrame into a `mikeio.DataArray`.
3.  Grouping these `DataArray` objects into a `mikeio.Dataset`.
4.  Writing this `Dataset` to a `.dfs0` file on your disk.

Let's walk through each of these stages.

## Preparing Your Pandas DataFrame

Before you can export your data, take a moment to ensure your `pandas` DataFrame is in good shape:

*   **`DatetimeIndex` is Key:** The DataFrame absolutely must have a `DatetimeIndex`. This is crucial as it provides the time information for your series.
*   **Meaningful Column Names:** The names of your columns will often become the item names in the `dfs0` file. Choose descriptive names that will make sense when you or others use the `dfs0` file later.
*   **Numeric Data Types:** Your data should be numeric, typically floats (like water levels or flow rates) or integers (like counts).

## Creating `mikeio.DataArray` Objects

A `mikeio.DataArray` is the `mikeio` object that represents a single time series—think of it as one item in a `dfs0` file. You will create one `DataArray` for each `pandas` Series (i.e., each column from your DataFrame) that you want to include in your output `dfs0` file.

To create a `DataArray`, you'll primarily need:
*   `data`: The `pandas` Series (or a NumPy array) containing your actual data values.
*   `time`: The `DatetimeIndex` from your `pandas` Series or DataFrame.
*   `item`: A `mikeio.ItemInfo` object. This is important as it describes the item's name, its type (e.g., water level, rainfall), and its unit. `mikeio` provides an enumeration called `mikeio.EUMType` for standard DHI item types.

Here's how you might create a `DataArray` from a `pandas` Series you've already processed:

```{{python}}
#| eval: false
#| echo: true
# Assuming 'processed_series' is your pandas Series (e.g., with flow data)
# and 'mikeio' is imported (import mikeio)
flow_item_info = mikeio.ItemInfo("SiteA_Flow_Processed", mikeio.EUMType.Discharge, mikeio.EUMUnit.m3_per_s)
flow_data_array = mikeio.DataArray(data=processed_series,
                                   time=processed_series.index,
                                   item=flow_item_info)
```

::: {.callout-tip}
## Item Information (`ItemInfo`, `EUMType`, and `EUMUnit`)
Specifying correct item information using `mikeio.ItemInfo`, including the `mikeio.EUMType` (e.g., `mikeio.EUMType.Rainfall` for precipitation data) and `mikeio.EUMUnit` (e.g., `mikeio.EUMUnit.mm_per_hour`), is vital for ensuring compatibility and proper interpretation within MIKE software. You can find a comprehensive list of available types and units in the [MIKE IO documentation on ItemInfo](https://dhi.github.io/mikeio/api-dfs.html#iteminfo). While you can use generic types if you're unsure, using specific, correct types and units is highly recommended for seamless integration with MIKE+ and other DHI tools.
:::

## Assembling `DataArray`s into a `mikeio.Dataset`

Once you have one or more `DataArray` objects, you'll collect them into a `mikeio.Dataset`. A `Dataset` is essentially a container that holds all the individual time series items you want to save together in one `dfs0` file.

Creating a `Dataset` is as simple as passing a list of your `DataArray` objects to the `mikeio.Dataset` constructor:

```{{python}}
#| eval: false
#| echo: true
# Assuming 'flow_data_array' is the DataArray created in the previous step
# and potentially other DataArrays like 'waterlevel_data_array'
# and 'mikeio' is imported
my_dataset = mikeio.Dataset([flow_data_array]) # Add more DataArrays to the list if needed
```

## Writing the `Dataset` to a `dfs0` File

With your `Dataset` prepared, the final step is to write it to a `.dfs0` file. This is done using the `.to_dfs()` method, which is available on your `Dataset` object. You simply need to provide the desired file path and name for your new `dfs0` file.

```{{python}}
#| eval: false
#| echo: true
# Assuming 'my_dataset' is the mikeio.Dataset created above
# and 'mikeio' is imported
output_filepath = "data/processed_timeseries.dfs0"
my_dataset.to_dfs(output_filepath)
```

And that's it! Your carefully processed time series data, originally in a `pandas` DataFrame, is now saved in the `dfs0` format, ready to be used in your MIKE+ projects or shared with colleagues.

## Video - Example: Creating a `dfs0` File (5-10 min)

*   Start with a processed `pandas` DataFrame.
*   Demonstrate creating `mikeio.DataArray` objects for a couple of columns, including setting basic `ItemInfo` (name, EUM Type, EUM Unit).
*   Show creating a `mikeio.Dataset` from these `DataArray`s.
*   Illustrate saving the `Dataset` to a new `.dfs0` file using `.to_dfs()`.
*   Optionally, briefly open the created `dfs0` file in a tool like MIKE Zero's Time Series Editor or plot it with `mikeio` again to verify its contents (if feasible to demonstrate quickly).