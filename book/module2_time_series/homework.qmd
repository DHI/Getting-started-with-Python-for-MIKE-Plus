# Homework {.unnumbered}

This homework assignment will give you practice in applying the concepts learned in Module 2 for handling time series data using `mikeio`, `pandas`, `matplotlib`, and `tsod`.

**Setup:**

*   Ensure you have `mikeio`, `pandas`, `matplotlib`, and `tsod` installed in your course project's virtual environment.
*   Download the provided time series file: `homework_module2_timeseries.dfs0` {download="homework_module2_timeseries.dfs0"}. (You'll need to create this dummy file or have it provided for the exercise to work).
    *   For this exercise, assume `homework_module2_timeseries.dfs0` contains hourly data for the year 2022 for at least two items: "Observed_WaterLevel" (in meters) and "Observed_Flow" (in m3/s). The water level data might have some anomalies.

```python
#| echo: false
#| include: false
# Create a dummy homework_module2_timeseries.dfs0 for students if it doesn't exist
# This code block is hidden from the student's view but ensures the file is available.
import pandas as pd
import numpy as np
import mikeio
from mikeio.eum import EUMType, EUMUnit
from pathlib import Path

homework_file = Path("homework_module2_timeseries.dfs0")
if not homework_file.exists():
    print(f"Creating dummy '{homework_file}' for homework...")
    time_idx = pd.date_range("2022-01-01 00:00:00", "2022-12-31 23:00:00", freq="H")
    
    # Water level with some anomalies
    wl_data = 5 + np.sin(np.linspace(0, 50, len(time_idx))) * 2
    wl_data[100] = 15  # Anomaly
    wl_data[500] = -2  # Anomaly
    wl_data[1000:1005] = 20 # Sustained anomaly / error
    
    flow_data = 20 + np.cos(np.linspace(0, 50, len(time_idx))) * 10 + np.random.rand(len(time_idx)) * 2

    da_wl = mikeio.DataArray(
        data=wl_data, time=time_idx,
        item=mikeio.ItemInfo("Observed_WaterLevel", EUMType.Water_Level, EUMUnit.meter)
    )
    da_flow = mikeio.DataArray(
        data=flow_data, time=time_idx,
        item=mikeio.ItemInfo("Observed_Flow", EUMType.Discharge, EUMUnit.cubic_meter_per_second)
    )
    mikeio.write_dfs0(str(homework_file), [da_wl, da_flow])
    print(f"Dummy '{homework_file}' created successfully.")
else:
    print(f"'{homework_file}' already exists.")
```

---

**Exercise 1: Setup and Data Loading**

1.  Create a new Python script (e.g., `module2_homework.py`) in your VS Code project.
2.  Import necessary libraries: `mikeio`, `pandas`, `numpy`, and `matplotlib.pyplot`. If you plan to use `tsod` detectors, import them as well.
3.  Define the filepath to `homework_module2_timeseries.dfs0`.
4.  Read the `.dfs0` file into a `mikeio` Dataset and then convert it to a Pandas DataFrame named `df_raw`.
5.  Print the `df_raw.head()` and `df_raw.info()` to understand its structure.
6.  List all available item names from the original `mikeio` Dataset object.

**Exercise 2: Data Selection and Initial Plotting**

1.  From `df_raw`, select only the "Observed_WaterLevel" data for the month of March 2022. Store this in a new DataFrame or Series called `df_wl_march`.
2.  Create a line plot of `df_wl_march`.
    *   Ensure the plot has an appropriate title (e.g., "Observed Water Level - March 2022").
    *   Label the x-axis ("Time") and y-axis ("Water Level (m)").
    *   Add a grid for better readability.
3.  Save this plot as an image file named `waterlevel_march_2022.png`.
4.  Display the plot.

**Exercise 3: Resampling**

1.  Take the full "Observed_Flow" data from `df_raw`.
2.  Downsample this hourly flow data to daily average flow values. Store the result in `df_flow_daily_avg`.
3.  Plot the original hourly "Observed_Flow" for January 2022 and the `df_flow_daily_avg` for January 2022 on the *same* graph.
    *   Use different colors and/or line styles for the two series.
    *   Add a legend to distinguish them.
    *   Provide a title and appropriate axis labels.
4.  Save this plot as `flow_jan_comparison.png` and display it.

**Exercise 4: Anomaly Detection and Cleaning (for "Observed_WaterLevel")**

1.  Focus on the "Observed_WaterLevel" Series from `df_raw` for the entire year.
2.  Use a `tsod` detector of your choice to identify anomalies. For example, you could use:
    *   A `SigmaDetector` (e.g., `window_size=24`, `n_sigma=3`).
    *   A `RangeDetector` if you have an idea of plausible min/max values (e.g., `min_val=0`, `max_val=10`).
    *   *(If using a specific detector, you might need to import it, e.g., `from tsod.detectors import SigmaDetector`)*
3.  Store the boolean mask of detected anomalies. Print the number of anomalies found.
4.  Create a new Series `wl_cleaned` by copying the original "Observed_WaterLevel" data. Replace the detected anomalies in `wl_cleaned` with `np.nan`.
5.  Fill the `NaN` values in `wl_cleaned` using linear interpolation.
6.  Create a plot comparing:
    *   The original "Observed_WaterLevel" for a period where you know anomalies exist (e.g., check where `tsod` found them or look at the data generation script if you made the dummy file).
    *   The `wl_cleaned` series (after NaN replacement and interpolation) for the same period.
    *   Highlight the original anomalies if possible (e.g., by plotting them as scatter points on top of the original line).
    *   Ensure titles, labels, and legends are clear.
7.  Save this plot as `waterlevel_cleaning_effect.png` and display it.

**Exercise 5: Creating a New dfs0 File**

1.  You now have a cleaned "Observed_WaterLevel" series (from Exercise 4, after interpolation) and the original "Observed_Flow" series from `df_raw`.
2.  Create a new `.dfs0` file named `processed_data_2022.dfs0`. This file should contain two items:
    *   The cleaned water level data.
    *   The original (or resampled daily average, if you prefer) flow data.
3.  For each item, define appropriate `mikeio.ItemInfo` including:
    *   A descriptive name (e.g., "Cleaned_WaterLevel", "Original_Flow_Hourly" or "Daily_Avg_Flow").
    *   The correct `EUMType` (e.g., `EUMType.Water_Level`, `EUMType.Discharge`).
    *   The correct `EUMUnit` (e.g., `EUMUnit.meter`, `EUMUnit.cubic_meter_per_second`).
4.  Write these items to the `processed_data_2022.dfs0` file.
5.  **Verification (Optional but Recommended):** Read your newly created `processed_data_2022.dfs0` file back into a Pandas DataFrame and print its `head()` and item information to confirm it was created correctly.

---

## Practice Exercises (Optional)

For further practice:

1.  **Explore other `tsod` detectors:** Try different anomaly detectors available in `tsod` (if you can find its documentation or examples) on the "Observed_WaterLevel" data and compare their results.
2.  **Different Resampling Aggregations:** Experiment with other aggregation methods for downsampling the flow data (e.g., `.min()`, `.max()`, `.median()`, `.sum()`). How do these change the resulting daily time series?
3.  **Handling Missing Data Before Anomaly Detection:** If your original data had `NaN` values *before* anomaly detection, how might you handle them? Would you fill them first, or would your `tsod` detector handle them? Research or experiment.
4.  Download the following Jupyter Notebook for more guided practice and challenges related to this module's topics:
    `module2_practice_notebook.ipynb` {download="module2_practice_notebook.ipynb"}
    *(Note: You would need to create and provide this notebook file.)*

Good luck! Remember to refer to the course materials and the documentation of the libraries if you get stuck.