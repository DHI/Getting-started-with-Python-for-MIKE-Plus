---
comments: false
---

# Homework {.unnumbered}

These exercises are designed to help you practice the concepts you've learned in Module 2. You'll get hands-on experience reading, manipulating, validating, and writing `dfs0` files using `mikeio`, `pandas`, and `tsod`.

**General Setup for Exercises:**

1.  Begin by creating a new subfolder named `module2_homework` within your main course project folder. This is where you'll save your scripts and data for these exercises.
2.  Before running any Python scripts, always ensure your `uv` virtual environment (which should include `pandas`, `matplotlib`, `mikeio`, and `tsod` from previous setups) is activated in your VS Code terminal.
3.  You'll need to download specific data files for some exercises; links are provided. Make sure to save these files directly into your `module2_homework` subfolder.

---

**Exercise 1: Project Setup and Reading `dfs0` Data**

First, download the sample time series file: [rain_data_raw.dfs0](data/homework/rain_data_raw.dfs0){download="rain_data_raw.dfs0"}. Save it into your `module2_homework` folder.
Now, create a new Python script in the same folder, perhaps naming it `process_rain_data.py`.

In your script, you'll start by importing the `mikeio` and `pandas` libraries.

```{python}
#| echo: true
import mikeio
import pandas as pd
```

With the libraries imported, read the `rain_data_raw.dfs0` file into a `mikeio` `Dataset`. Then, convert this `Dataset` into a `pandas` DataFrame, which will make it easier to work with.

```{python}
#| echo: true
#| output: false
# Make sure 'rain_data_raw.dfs0' is in your 'module2_homework' folder
dfs0_file_path = "rain_data_raw.dfs0"
ds = mikeio.read(dfs0_file_path)
df_rain_raw = ds.to_dataframe()
```

To get a first look at your data's structure, print the head and info of the DataFrame. This will show you the first few rows and provide a summary of columns, data types, and non-null values.

```{python}
#| echo: true
#| output: true
# Assuming df_rain_raw is your DataFrame from the previous step
# print(df_rain_raw.head()) # Uncomment to view the first few rows
# df_rain_raw.info()      # Uncomment to view DataFrame summary
print("Examine the output from df_rain_raw.head() and df_rain_raw.info() in your console.")
```

Take a moment to observe the output in your terminal. What are the item names? What is the time range of the data?

**Exercise 2: Data Selection**

Using the `df_rain_raw` DataFrame from Exercise 1, let's practice selecting specific data.

1.  The `dfs0` file might contain data from multiple rainfall gauges. Your task is to select data for only one specific gauge. If an item named "Gauge_A2" exists (check your `.info()` output from Exercise 1), use that. Otherwise, pick any one available item name from your DataFrame. Store this selected data in a new DataFrame or Series.

    ```{python}
    #| echo: true
    #| output: false
    # Replace "Gauge_A2" if it doesn't exist, with an actual item name from your df_rain_raw
    # For example, if your first column name is 'Rainfall_Gauge1', use that.
    # selected_item_name = df_rain_raw.columns[0] # A way to pick the first item if unsure
    selected_item_name = "Gauge_A2" # Or your chosen item name
    single_gauge_data = df_rain_raw[[selected_item_name]] # Use double brackets to keep it a DataFrame
    # or single_gauge_series = df_rain_raw[selected_item_name] # For a Series
    ```

2.  From this `single_gauge_data`, further refine your selection to include records only for a specific period. Let's aim for the entire month of July 2022. If your data's time range is different, please adjust the year and month accordingly to select a single month's worth of data.

    ```{python}
    #| echo: true
    #| output: false
    # Assuming single_gauge_data has a DatetimeIndex
    # Adjust '2022-07' if your data has a different time range
    july_2022_data = single_gauge_data.loc["2022-07"]
    ```

    ::: {.callout-tip}
    Remember that `pandas` allows for partial string indexing for `DatetimeIndex`. For example, `df.loc["2022"]` would select all data for the year 2022, and `df.loc["2022-07"]` selects all data for July 2022.
    :::

3.  Finally, print the `.head()` of this time-filtered data to see the result.

    ```{python}
    #| echo: true
    #| output: true
    # print(july_2022_data.head()) # Uncomment to view the result
    print("Examine the head of your July 2022 data in the console.")
    ```

**Exercise 3: Resampling Time Series**

Now, let's work with the `single_gauge_data` (containing the full period for your selected gauge, before the July 2022 selection). If you overwrote it, reload it from `df_rain_raw`.

1.  The raw data is likely at a fine temporal resolution (e.g., 5-minute or 10-minute). Your task is to resample this data to calculate the **total hourly rainfall**.

    ```{python}
    #| echo: true
    #| output: false
    # Assuming single_gauge_data is your DataFrame/Series with a DatetimeIndex
    hourly_rainfall_total = single_gauge_data.resample('H').sum()
    ```

2.  Print the `.head()` of the hourly resampled DataFrame to verify your operation.

    ```{python}
    #| echo: true
    #| output: true
    # print(hourly_rainfall_total.head()) # Uncomment to view
    print("Examine the head of your hourly resampled rainfall data.")
    ```

3.  *Optional Challenge:* Resample the same `single_gauge_data` to determine the **mean daily rainfall**. Print its `.head()`.

**Exercise 4: Basic Anomaly Detection with `tsod`**

We'll use the **hourly resampled rainfall Series** (or the first column of `hourly_rainfall_total` if it's a DataFrame) from Exercise 3 for this task.

1.  Import a suitable detector from the `tsod` library. For rainfall, `tsod.RangeOutlierDetector` could be useful if you know reasonable minimum (e.g., 0) and maximum plausible hourly intensities. Alternatively, `tsod.StddevOutlierDetector` can identify points that deviate significantly from the mean. Let's try `StddevOutlierDetector` with a multiplier of 3.

    ```{python}
    #| echo: true
    #| output: false
    from tsod.detectors import StddevOutlierDetector
    import numpy as np # tsod might return NaNs which are fine

    # If hourly_rainfall_total is a DataFrame, select the series:
    # hourly_rainfall_series = hourly_rainfall_total[selected_item_name]
    # If it's already a Series, you can use it directly.
    # For this example, let's assume it's a series:
    # hourly_rainfall_series = hourly_rainfall_total # if it was a series
    # Ensure you have a pandas Series for the detector
    if isinstance(hourly_rainfall_total, pd.DataFrame):
        hourly_rainfall_series = hourly_rainfall_total.iloc[:, 0] # take the first column
    else:
        hourly_rainfall_series = hourly_rainfall_total
    
    detector = StddevOutlierDetector(window_size=5, n_stddev=3) # Example parameters
    ```

2.  Apply the initialized detector to your hourly rainfall Series. The `.detect()` method is typically used.

    ```{python}
    #| echo: true
    #| output: false
    # The detect method often returns a boolean Series
    outliers_bool_series = detector.detect(hourly_rainfall_series)
    ```

3.  The result from the detector is often a boolean Series (True for outliers, False otherwise). Determine how many outliers were detected by summing this boolean Series.

    ```{python}
    #| echo: true
    #| output: true
    # num_outliers = outliers_bool_series.sum()
    # print(f"Number of outliers detected: {num_outliers}")
    print("The sum of the boolean outlier series will show the count of outliers.")
    ```

**Exercise 5: Handling Anomalies and Missing Data**

Continuing with your hourly rainfall Series (`hourly_rainfall_series`) and the `outliers_bool_series` from Exercise 4:

1.  A common strategy is to replace identified outliers with `np.nan` (Not a Number). First, ensure you've imported `numpy`. Then, use the boolean series to mark outliers as `np.nan` in your rainfall series.

    ```{python}
    #| echo: true
    #| output: false
    import numpy as np

    hourly_rainfall_cleaned = hourly_rainfall_series.copy() # Work on a copy
    hourly_rainfall_cleaned[outliers_bool_series] = np.nan
    ```

2.  Verify by checking how many `NaN` values are now present in your `hourly_rainfall_cleaned` Series using `.isna().sum()`.

    ```{python}
    #| echo: true
    #| output: true
    # nan_count = hourly_rainfall_cleaned.isna().sum()
    # print(f"Number of NaN values after marking outliers: {nan_count}")
    print("Check the count of NaN values in your console.")
    ```

3.  Now, fill these `NaN` values. A simple and often effective method for time series is `ffill` (forward fill), which propagates the last valid observation forward.

    ```{python}
    #| echo: true
    #| output: false
    hourly_rainfall_filled = hourly_rainfall_cleaned.fillna(method='ffill')
    # You might still have NaNs at the beginning if the series started with outliers
    # Consider a .bfill() as well if needed, or a specific value fill.
    hourly_rainfall_filled = hourly_rainfall_filled.fillna(0) # Example: fill remaining NaNs with 0
    ```

4.  Print the `.head()` of this fully cleaned and filled Series to see the result.

    ```{python}
    #| echo: true
    #| output: true
    # print(hourly_rainfall_filled.head()) # Uncomment to view
    print("Examine the head of your cleaned and filled rainfall data.")
    ```

**Exercise 6: Creating a New `dfs0` File**

Let's use the cleaned and filled hourly rainfall `pandas` Series (`hourly_rainfall_filled`) from Exercise 5 to create a new `dfs0` file.

1.  First, create a `mikeio.DataArray` from this Series. It's important to provide not only the data and time index but also appropriate item information using `mikeio.ItemInfo`. This includes a name for your item, its type (e.g., `mikeio.EUMType.Rainfall`), and its unit (e.g., `mikeio.EUMUnit.mm_per_hour` if you summed hourly rainfall in mm).

    ```{python}
    #| echo: true
    #| output: false
    from mikeio.eum import EUMType, EUMUnit

    # Ensure hourly_rainfall_filled is a pandas Series with a DatetimeIndex
    item_name_processed = f"Processed_{selected_item_name}_Hourly"
    
    data_array = mikeio.DataArray(
        data=hourly_rainfall_filled, # Your pandas Series
        time=hourly_rainfall_filled.index,
        item=mikeio.ItemInfo(name=item_name_processed, itemtype=EUMType.Rainfall, unit=EUMUnit.mm_per_hour)
    )
    ```
    ::: {.callout-note}
    Refer to the [MIKE IO documentation](https://dhi.github.io/mikeio/api-dfs.html#iteminfo) for more details on `ItemInfo`, `EUMType`, and `EUMUnit` to ensure your data is correctly described for MIKE software.
    :::

2.  Next, create a `mikeio.Dataset` which will contain your `DataArray`. A `Dataset` can hold multiple `DataArray`s, but for this exercise, one is sufficient.

    ```{python}
    #| echo: true
    #| output: false
    dataset_to_save = mikeio.Dataset([data_array])
    ```

3.  Finally, write this `Dataset` to a new `dfs0` file. Name it `processed_hourly_rain.dfs0` and save it in your `module2_homework` folder.

    ```{python}
    #| echo: true
    #| output: false
    output_dfs0_path = "processed_hourly_rain.dfs0"
    dataset_to_save.to_dfs(output_dfs0_path)
    print(f"Processed data saved to {output_dfs0_path}")
    ```
    You've now successfully created a `dfs0` file from your processed `pandas` data!

**Exercise 7 (Optional): Visualization**

To better understand the impact of your data processing steps, use `matplotlib` (which you encountered in Module 1) to create a comparative plot.

1.  Generate a plot that displays:
    *   The original hourly resampled data (from Exercise 3, e.g., `hourly_rainfall_series`).
    *   The data after replacing outliers with `np.nan` (from Exercise 5, e.g., `hourly_rainfall_cleaned`).
    *   The final cleaned and filled data (from Exercise 5, e.g., `hourly_rainfall_filled`).

    Plotting them on the same axes can be effective, or use subplots if that's clearer for your data. This will help you visually assess the changes made during the validation and cleaning process.

    ```{python}
    #| echo: true
    #| output: true # Set to true to see plot in supported environments, or save to file
    import matplotlib.pyplot as plt

    # plt.figure(figsize=(12, 6))
    # hourly_rainfall_series.plot(label='Original Hourly Resampled', alpha=0.7)
    # hourly_rainfall_cleaned.plot(label='Outliers as NaN', linestyle='--', alpha=0.7)
    # hourly_rainfall_filled.plot(label='Cleaned and Filled', linestyle=':', alpha=0.9)
    # plt.title(f'Rainfall Data Processing for {selected_item_name}')
    # plt.xlabel('Time')
    # plt.ylabel('Hourly Rainfall (mm)') # Adjust unit if different
    # plt.legend()
    # plt.show() # Or plt.savefig('comparison_plot.png')
    print("Uncomment the matplotlib code to generate and display/save your comparison plot.")
    ```

---

## Practice Exercises (Optional) {.unnumbered}

For additional practice and to reinforce your learning:

*   Download the [optional_flow_data.dfs0](data/homework/optional_flow_data.dfs0){download="optional_flow_data.dfs0"} file.
*   Try applying the full workflow you've just practiced (read, select, resample if appropriate, validate with `tsod`, clean, and write to a new `dfs0`) to this flow data.
*   Experiment with different `tsod` detectors or adjust their parameters. How do these changes affect the outcome?
*   Explore various `NaN` filling strategies (e.g., `bfill`, `interpolate`, filling with a mean or median) and observe their impact on the data, perhaps by plotting.
*   A Jupyter Notebook with guided solutions or further exploration for these optional exercises can be found here: [link_to_optional_notebook.ipynb](notebooks/M2_Optional_Practice.ipynb){download="M2_Optional_Practice.ipynb"} (This is a placeholder link; a notebook may be provided separately by your instructor).