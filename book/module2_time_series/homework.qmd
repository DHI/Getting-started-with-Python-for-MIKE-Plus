# Homework {.unnumbered}

These exercises are designed to help you solidify your understanding of the concepts covered in Module 2. You'll get hands-on practice reading, manipulating, validating, and writing `dfs0` files using the powerful combination of `mikeio`, `pandas`, and `tsod`.

**General Setup for Exercises:**

1.  Within your main course project folder, create a new subfolder dedicated to this module's homework, for example, `module2_homework`.
2.  Before running any scripts, ensure that your `uv` virtual environment, which includes `pandas`, `matplotlib`, `mikeio`, and `tsod`, is activated in your VS Code terminal.
3.  You will need to download data files for specific exercises; these will be linked directly in the exercise instructions. Make sure to save them into your `module2_homework` subfolder.

---

**Exercise 1: Project Setup and Reading `dfs0`**

1.  Download the sample time series file: [rain_data_raw.dfs0](data/homework/rain_data_raw.dfs0){download="rain_data_raw.dfs0"}. Save it into your `module2_homework` folder.
2.  Create a new Python script file within your `module2_homework` folder, for instance, `process_rain_data.py`.
3.  In your script, begin by importing the necessary libraries:

    ```{python}
    #| output: false
    import mikeio
    import pandas as pd
    ```

4.  Continue your script to:
    *   Read the `rain_data_raw.dfs0` file into a `mikeio` `Dataset` object.
    *   Convert this `Dataset` object into a `pandas` DataFrame.
    *   Print the `.head()` and `.info()` of the DataFrame.
    Now, write the Python code to perform these steps. After running your script, observe the output in your terminal to understand the DataFrame's initial structure and data types.

**Exercise 2: Data Selection**

Using the DataFrame you created in Exercise 1:

1.  The `dfs0` file might contain data from multiple rainfall gauges. Let's say you are specifically interested in a gauge named "Gauge_A2". If this item name doesn't exist in your data (check the output from `.info()` in Exercise 1), please choose one of the available item names. Select only this item's data into a new DataFrame or Series. You can achieve this using standard `pandas` column selection, for example, `your_df['item_name_here']`.
2.  From this single selected item's data, narrow down your focus further. Select only the records for a specific period, such as the entire month of July 2022. (Adjust the year and month if your dataset's time range is different). Remember, `pandas` allows slicing a `DatetimeIndex` with string representations of dates, like `your_series['YYYY-MM']`.
3.  Print the `.head()` of this finally selected, time-filtered data to verify your selection.

**Exercise 3: Resampling Time Series**

Using the full-period data for the single item you selected in Exercise 2 (e.g., "Gauge_A2", *before* the time range selection in step 2.2, or reload it if that's simpler):

1.  The raw data is often at a fine temporal resolution (e.g., 5-minute or 10-minute intervals). Your task is to resample this data to calculate the **total hourly rainfall**. You'll use the `.resample()` method in `pandas` with an appropriate rule (e.g., `'H'` for hourly) followed by an aggregation method like `.sum()`.
2.  Print the `.head()` of the resulting hourly resampled DataFrame.
3.  *Optional Challenge:* Resample the same original data to determine the **mean daily rainfall**. Print the `.head()` of this daily data as well.

**Exercise 4: Basic Anomaly Detection with `tsod`**

Now, take the **hourly resampled rainfall Series** you generated in Exercise 3:

1.  Import an appropriate outlier detector from the `tsod` library. For instance, you could use `tsod.RangeOutlierDetector` if you have a good idea of reasonable minimum/maximum rainfall intensity, or `tsod.StddevOutlierDetector` with a multiplier (e.g., 3 standard deviations).

    ```{python}
    #| output: false
    # Example import, choose one or explore others
    from tsod import StddevOutlierDetector 
    # from tsod import RangeOutlierDetector 
    import numpy as np # We'll likely need numpy later
    ```

2.  Instantiate and apply your chosen detector to your hourly rainfall Series. This typically involves creating an instance of the detector class and then calling its `.detect()` method on your `pandas` Series.
3.  The detector will usually return a boolean Series, where `True` indicates a potential outlier. Print the total number of outliers detected by using `.sum()` on this boolean Series (since `True` values are treated as 1 and `False` as 0 in a sum).

**Exercise 5: Handling Anomalies and Missing Data**

Continuing with the hourly rainfall Series and the detected outliers from Exercise 4:

1.  A common strategy for handling identified outliers is to replace them with `np.nan` (Not a Number). Use the boolean Series from your `tsod` detector to assign `np.nan` to the outlier locations in your hourly rainfall Series. (You've already imported `numpy as np` in the previous step's example).
2.  Verify your action by checking how many `NaN` values are now present in your Series using `.isna().sum()`.
3.  Now, fill these `NaN` values. A simple and often effective method for time series data is forward fill (`ffill`). Apply this using the `.fillna(method='ffill')` method on your Series.
4.  Print the `.head()` of the cleaned (outliers replaced and `NaN`s filled) Series to see the result.

**Exercise 6: Creating a New `dfs0` File**

With the cleaned (outliers handled, `NaN`s filled) hourly rainfall `pandas` Series from Exercise 5, let's save it back to a `dfs0` file:

1.  Create a `mikeio.DataArray` from your cleaned `pandas` Series. When doing so, you'll need to provide the data itself, the time index, and crucial metadata via a `mikeio.ItemInfo` object. For example:

    ```python
    #| output: false
    #| include: false
    # Assume 'cleaned_series' is your pandas Series from Exercise 5
    # and 'mikeio' is imported. This is a conceptual setup.
    # For the actual exercise, you'll use your actual Series.
    import pandas as pd
    import mikeio
    # Dummy data for demonstration of ItemInfo structure
    idx = pd.date_range("2023-01-01", periods=5, freq="H")
    data = [1,2,3,4,5]
    cleaned_series = pd.Series(data=data, index=idx)
    # End dummy data
    ```

    Now, to create the `DataArray`:
    
    ```{python}
    #| eval: false
    # This is an example structure; adapt it with your actual 'cleaned_series'
    item_name = "Processed_Rainfall_Gauge_A2"
    item_type = mikeio.EUMType.Rainfall 
    item_unit = mikeio.EUMUnit.mm_per_hour # Adjust if your sum was total mm

    da = mikeio.DataArray(
        data=cleaned_series.values, # Use .values for numpy array
        time=cleaned_series.index,
        item=mikeio.ItemInfo(name=item_name, itemtype=item_type, unit=item_unit)
    )
    ```
    Adjust the `name`, `itemtype`, and `unit` as appropriate for your data. For instance, if your hourly sum represents total millimeters for that hour, `mikeio.EUMUnit.mm_per_hour` (or simply `mikeio.EUMUnit.mm` if the rate aspect is implied by the hourly step) would be suitable.

2.  Next, create a `mikeio.Dataset` to hold your `DataArray`. A `Dataset` is essentially a list of `DataArray`s.
    
    ```{python}
    #| eval: false
    # Assuming 'da' is the DataArray from the previous step
    ds = mikeio.Dataset([da])
    ```

3.  Finally, write this `Dataset` to a new `dfs0` file. Name it `processed_hourly_rain.dfs0` and save it in your homework folder. Use the `.to_dfs()` method of the `Dataset` object.
    
    ```{python}
    #| eval: false
    # Assuming 'ds' is the Dataset from the previous step
    output_filepath = "processed_hourly_rain.dfs0" 
    ds.to_dfs(output_filepath)
    print(f"Processed data saved to {output_filepath}")
    ```

**Exercise 7 (Optional): Visualization**

To better understand the impact of your data processing steps:

1.  Using `matplotlib` (which you encountered in Module 1), create a plot that visualizes the following three Series:
    *   The original hourly resampled data (from Exercise 3, before any outlier handling).
    *   The data after you replaced the detected outliers with `np.nan` (from Exercise 5, before filling).
    *   The final cleaned and filled data (from Exercise 5, after filling `NaN`s).
    Plot them on the same axes for direct comparison, or on separate subplots if that's clearer. This will help you visually assess the changes made during the cleaning process. Remember to import `matplotlib.pyplot as plt`.

---

## Practice Exercises (Optional) {.unnumbered}

For those looking for more practice, consider these additional tasks:

*   Download the [optional_flow_data.dfs0](data/homework/optional_flow_data.dfs0){download="optional_flow_data.dfs0"} file. This file contains flow data.
*   Apply the complete workflow you've learned:
    1.  Read the `dfs0` file.
    2.  Select a specific item or time range if desired.
    3.  Resample the data if appropriate for its type (e.g., calculating daily averages from hourly flow).
    4.  Validate the data using a `tsod` detector.
    5.  Clean the data by handling outliers and filling `NaN`s.
    6.  Write the processed data to a new `dfs0` file.
*   Experiment with different `tsod` detectors or adjust the parameters of the detectors you've already used. Observe how these changes affect outlier detection.
*   Explore various `NaN` filling strategies (e.g., `bfill`, linear interpolation with `.interpolate()`, or filling with the mean/median of the series). Visualize and consider the impact of each method on your time series.

For a guided approach to these optional exercises or further exploration, you can refer to the supplementary Jupyter Notebook: [M2_Optional_Practice.ipynb](notebooks/M2_Optional_Practice.ipynb){download="M2_Optional_Practice.ipynb"} (Note: This is a placeholder filename; the actual notebook will be provided with the course materials).

---
comments: false
---