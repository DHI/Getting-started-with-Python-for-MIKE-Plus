# Writing DFS0 Files

This section focuses on the crucial step of exporting your processed data back into a format MIKE+ can understand. The primary goal is to convert a Pandas DataFrame, perhaps containing cleaned rainfall data, into a DFS0 file. The typical workflow involves transforming the Pandas DataFrame into a `mikeio.Dataset` object, and then writing this `Dataset` to a DFS0 file.

## DataFrame to `Dataset`: Basic

First, let's assume you have a Pandas DataFrame ready. For instance, here's a look at a simple DataFrame, `df_rain`, containing some rainfall data with a `DatetimeIndex`:

```{python}
import pandas as pd
import mikeio

# Sample DataFrame (replace with actual data loading in a real scenario)
time_index = pd.to_datetime(["2023-01-01 00:00", "2023-01-01 01:00", "2023-01-01 02:00"])
data_values = {"Rainfall_mm": [0.5, 1.2, 0.8]}
df_rain = pd.DataFrame(data_values, index=time_index)
df_rain.head()
```

Converting this DataFrame to a basic `mikeio.Dataset` is straightforward using `mikeio.from_pandas()`:

```{python}
ds_basic = mikeio.from_pandas(df_rain)
ds_basic
```

::: {.callout-tip}
Ensure your DataFrame's index is a `DatetimeIndex` for time series DFS0 files. This is crucial for MIKE IO to correctly interpret the time information.
:::

## Item Metadata: `ItemInfo`

While the basic conversion works, MIKE software requires specific metadata for each data item, such as its type, unit, and how values are interpreted over time. This is where `mikeio.ItemInfo` comes in. If we inspect the items of our `ds_basic` created above, you'll notice default, often incorrect, metadata:

```{python}
ds_basic.items
```

::: {.callout-note}
Without custom `ItemInfo`, `mikeio` uses default values. These often need adjustment, especially `itemtype`, `unit`, and `data_value_type`, to ensure MIKE+ interprets your data correctly.
:::

The `mikeio.ItemInfo` class allows you to define these essential properties for each item in your dataset:

*   `name`: (str) The name of the item, typically derived from your DataFrame column name.
*   `itemtype`: (A `mikeio.EUMType` object) This is a DHI-specific enumeration defining the physical quantity (e.g., `mikeio.EUMType.Rainfall` for rainfall, `mikeio.EUMType.Water_Level` for water level).
*   `unit`: (A `mikeio.EUMUnit` object) This is a DHI-specific enumeration for the unit of measurement (e.g., `mikeio.EUMUnit.mm` for millimeters, `mikeio.EUMUnit.meter` for meters).
*   `data_value_type`: (str) This string specifies how the data values relate to the time steps. The default is ‘Instantaneous’. Other common options include:
    *   ‘Instantaneous’: Value at a specific point in time.
    *   ‘Accumulated’: Value accumulated over the entire period up to the timestamp.
    *   ‘StepAccumulated’: Value accumulated over the preceding time step.
    *   ‘MeanStepBackward’: Average value over the preceding time step.
    *   ‘MeanStepForward’: Average value over the following time step.

::: {.callout-note}
Refer to the MIKE+ documentation or the DHI EUM documentation for precise definitions and appropriate use of each `data_value_type`.
:::

For example, to define `ItemInfo` for our rainfall data, which is measured in millimeters and, for this example, we'll consider it as an accumulated value:

```{python}
from mikeio import ItemInfo
from mikeio.eum import EUMType, EUMUnit

# Re-using df_rain from the previous example, but changing column name for clarity in this ItemInfo example
df_rain.columns = ["Rainfall_Gauge1"]

rainfall_item_info = ItemInfo(
    name="Rainfall_Gauge1", 
    itemtype=EUMType.Rainfall,
    unit=EUMUnit.mm,
    data_value_type="Accumulated" 
)
rainfall_item_info
```

::: {.callout-tip}
Providing accurate `ItemInfo` is key for ensuring compatibility with MIKE software and correctly interpreting the meaning of your data within the MIKE ecosystem.
:::

## Specifying `ItemInfo` on Conversion

To use your custom `ItemInfo` when converting a DataFrame, you pass a list of `ItemInfo` objects to the `items` argument of `mikeio.from_pandas()`. Each `ItemInfo` object in the list should correspond to a column in your DataFrame that you want to include in the `Dataset`. The `name` attribute of the `ItemInfo` object is used to map it to the correct DataFrame column.

Here's how you convert the `df_rain` DataFrame (with the "Rainfall_Gauge1" column) using the `rainfall_item_info` we defined:

```{python}
# df_rain and rainfall_item_info are from previous code blocks
ds_with_custom_info = mikeio.from_pandas(df_rain, items=[rainfall_item_info])
ds_with_custom_info.items
```

## `Dataset` to DFS0 File

The final step is to save your carefully prepared `Dataset` object, now containing the correct data and metadata, to a DFS0 file. This is done using the `.to_dfs()` method of the `Dataset` object. You simply provide the desired output file path.

```{python}
# ds_with_custom_info is from the previous code block
output_file_path = "data/rainfall_processed.dfs0"
ds_with_custom_info.to_dfs(output_file_path)
```

This will create a file named `rainfall_processed.dfs0` in your 'data' directory (ensure this directory exists or adjust the path accordingly). You can then use this DFS0 file in your MIKE+ models or other DHI software.