# Data Validation and Cleaning with `tsod` and `pandas`

This section explores how to combine the outlier detection capabilities of the `tsod` package with the versatile data manipulation tools in `pandas` to validate your time series data. Effective data validation often involves identifying anomalous data points and then deciding how to handle these values, which might include replacing them or filling gaps.

## Detecting Anomalies with `tsod`

The first step in data validation is often to detect unusual data points, or outliers. The `tsod` package provides various algorithms for this purpose. Let's imagine we have a `pandas` Series containing time series data.

First, we'll create a sample `pandas` Series to work with. This series has a `DatetimeIndex` and some numerical values, one of which (55.5) looks like an outlier compared to the others.

```{python}
import pandas as pd
import numpy as np

data = {'timestamp': pd.to_datetime(['2023-01-01 00:00', '2023-01-01 01:00', 
                                     '2023-01-01 02:00', '2023-01-01 03:00', 
                                     '2023-01-01 04:00', '2023-01-01 05:00']),
        'value': [10.1, 10.2, 55.5, 10.4, 9.8, 10.0]}
my_time_series = pd.Series(data['value'], index=data['timestamp'])
my_time_series
```

Now, we can apply a conceptual detector from `tsod`. For instance, `tsod` might offer a range-based detector that flags values outside a specified minimum and maximum. While the actual `tsod` functions might differ, the principle is to get a boolean Series indicating which data points are considered outliers. Here, `True` will mark an outlier.

```{python}
# For demonstration, let's define a conceptual tsod-like range detector
def conceptual_tsod_range_detector(series, min_val, max_val):
    return ~series.between(min_val, max_val)

is_outlier = conceptual_tsod_range_detector(my_time_series, 
                                            min_val=9.0, 
                                            max_val=11.0)
is_outlier
```

The `is_outlier` Series now flags the value `55.5` as `True`, indicating it's outside our defined "normal" range.

## Marking Anomalies as `NaN`

Once outliers are identified, a common strategy is to replace them with `NaN` (Not a Number). This explicitly marks the data as missing or unreliable, and `pandas` has excellent tools for subsequently handling these `NaN` values.

::: {.callout-note}
## `numpy.nan` for Missing Data
`np.nan` is the standard way to represent missing or undefined numerical data in `pandas` and `numpy`. To use it, you typically need to import `numpy` first, which we've done with `import numpy as np`.
:::

Using the `is_outlier` boolean Series, we can easily select the outlier values in our original Series and assign `np.nan` to them. It's good practice to work on a copy of your data if you want to preserve the original.

```{python}
series_with_nans = my_time_series.copy()
series_with_nans[is_outlier] = np.nan
series_with_nans
```

You can see that `55.5` has now been replaced with `NaN`.

## Strategies for Filling `NaN` Values using `pandas`

After marking data as `NaN`, or if your dataset initially contains missing values, you'll often need to fill these gaps. Many analytical models and statistical functions cannot process `NaN` values or might produce misleading results. `pandas` offers several convenient methods through its `.fillna()` and `.interpolate()` functions.

### Forward Fill (`ffill`)

Forward fill propagates the last valid observation forward to fill `NaN`s. This method is often suitable for sensor data where values tend to persist over short periods.

```{python}
series_ffilled = series_with_nans.fillna(method='ffill')
series_ffilled
```

### Backward Fill (`bfill`)

Backward fill works in the opposite direction, propagating the next valid observation backward to fill `NaN`s.

```{python}
series_bfilled = series_with_nans.fillna(method='bfill')
series_bfilled
```

### Interpolation

Interpolation fills `NaN` values using various mathematical techniques. Linear interpolation, the default for `interpolate()`, draws a straight line between the valid data points surrounding the gap.

```{python}
series_interpolated = series_with_nans.interpolate(method='linear')
series_interpolated
```

### Filling with a Constant

You can also fill `NaN`s with a specific constant value, such as zero, or a calculated statistic like the mean or median of the series.

```{python}
mean_value = series_with_nans.mean() # Calculate mean excluding NaNs
series_filled_mean = series_with_nans.fillna(mean_value)
series_filled_mean
```

::: {.callout-caution}
## Choosing a Filling Method
The choice of `NaN` filling method is critical and depends heavily on the nature of your data and the goals of your analysis.
*   `ffill` or `bfill` can be appropriate if values are expected to remain stable.
*   Interpolation might provide a smoother result but could create artificial data trends if gaps are large.
*   Filling with a mean or median can reduce the overall variance of the dataset and mask important data features.
Always consider the implications of your chosen method and visualize the results.
:::

Visualizing your time series before and after outlier handling and `NaN` filling is a crucial step. Plotting helps you assess the impact of these operations and ensure the cleaned data is suitable for your subsequent analyses or modeling tasks.

## Video - Example: Anomaly Detection and `NaN` Handling (5-10 min)

This video demonstrates a practical workflow:
*   Showing a `pandas` Series with some apparent outliers.
*   Applying a conceptual `tsod` detector.
*   Using the `tsod` output to set outliers to `np.nan`.
*   Illustrating `ffill` and `interpolate` methods on the Series.
*   Briefly plotting the original, `NaN`-marked, and filled series to show the effects.

{{< video https://www.youtube.com/embed/placeholder_video_id >}}